{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qjGPtk48jLT7"
      },
      "source": [
        "# CSE 576 (Spring 2020) Homework 4\n",
        "\n",
        "Welcome friends, it's time for Deep Learning with PyTorch! This homework might need a longer running time. \n",
        "Keep this in mind and start early.\n",
        "\n",
        "PyTorch is a deep learning framework for fast, flexible experimentation. We are going to use it to train our classifiers.\n",
        "\n",
        "For this homework you need to turn in this file `hw4.ipynb` after running your results and answering questions in-line.\n",
        "\n",
        "**Notes**: \n",
        " - This assignment was designed to be used with Google Colab, but feel free to set up your own environment if you wish. Just bear in mind that we cannot provide support for custom environments.\n",
        " - Feel free to create new cells as needed, but please **do not delete existing cells**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GGQCcvq84eP",
        "colab_type": "text"
      },
      "source": [
        "Before you get started, we suggest you do the [PyTorch tutorial first](https://github.com/param087/Pytorch-tutorial-on-Google-colab).\n",
        "\n",
        "You should at least do the 60 Minute Blitz up until \"Training a Classifier\".\n",
        "\n",
        "**How to use this notebook:**\n",
        " - Each cell with a grey background is executable.\n",
        " - They can be executed by pressing the \"Play\" button or by hitting `Shift+Enter`\n",
        " - Cells can be executed out of order.\n",
        " - You can add new cells by clicking on the `+ Code` button in the header.\n",
        " - Check out this [Colab Introduction](https://colab.research.google.com/notebooks/intro.ipynb#scrollTo=5fCEDCU_qrC0) if you're having trouble."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ytzMI9eMGZcF"
      },
      "source": [
        "## Setup\n",
        "\n",
        "This will set up the environment without GPUs. This is the recommended setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Cn6ci5wb84eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install torch==1.5.0+cpu torchvision==0.6.0+cpu -f https://download.pytorch.org/whl/torch_stable.html \n",
        "! pip install tqdm matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b37CIwsc84eT",
        "colab_type": "text"
      },
      "source": [
        "### With GPUs\n",
        "If you're feeling adventurous you can use GPUs to accelerate training. Follow the following steps. Just note that GPUs might not be available. The course staff also can't provide support for GPU-related issues so if you're having trouble please just use the CPU runtime.\n",
        "\n",
        " 1. Go to Runtime > Change runtime type and select 'GPU'\n",
        " 2. Restart the Runtime, uncomment the commands below and run them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xidZAA_bjL1G",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# Install the necessary packages\n",
        "\n",
        "# ! pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "# ! pip install tqdm matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTRfzE_s84eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set this flag.\n",
        "use_gpu = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsBJga6584ec",
        "colab_type": "text"
      },
      "source": [
        "### Check that things are working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gy8bYB-YXilT",
        "colab": {}
      },
      "source": [
        "# Make sure things work.\n",
        "\n",
        "import torch\n",
        "torch.zeros(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T5Zp2dQmYIsH"
      },
      "source": [
        " ## Initialize Datasets\n",
        "\n",
        " This code defines the data loaders that will be used to train and test our networks. It also defines data augmentation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WZ1otUNqX08V",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "default_train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "default_test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n",
        "])\n",
        "\n",
        "\n",
        "def get_train_loader(batch_size, transform=default_train_transform):\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', \n",
        "        train=True, \n",
        "        download=True, \n",
        "        transform=transform)\n",
        "    return torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "def get_test_loader(batch_size, transform=default_test_transform):\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', \n",
        "        train=False, \n",
        "        download=True, \n",
        "        transform=transform) \n",
        "    return torch.utils.data.DataLoader(\n",
        "        testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "# This downloads the datasets.\n",
        "get_train_loader(1)\n",
        "get_test_loader(1);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtwZwWdp84ej",
        "colab_type": "text"
      },
      "source": [
        "## Define code that trains and tests code.\n",
        "\n",
        "This code will train your model. Feel free to read the code below, but we suggest you don't modify it unless you know what you're doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fsHmTDLQkBgU",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def train(net, loader, optimizer, criterion, epoch, use_gpu=False):\n",
        "    running_loss = 0.0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    if use_gpu:\n",
        "        net = net.cuda()\n",
        "    else:\n",
        "        net = net.cpu()\n",
        "\n",
        "    pbar = tqdm(loader)\n",
        "    for i, data in enumerate(pbar):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_description(f\"[epoch {epoch+1}] loss = {running_loss/(i+1):.03f}\")\n",
        "    \n",
        "    average_loss = total_loss / (i + 1)\n",
        "    tqdm.write(f\"Epoch {epoch} summary -- loss = {average_loss:.03f}\")\n",
        "    \n",
        "    return average_loss\n",
        "\n",
        "\n",
        "def test(net, loader, tag='', use_gpu=False):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net = net.cuda() if use_gpu else net.cpu()\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            if use_gpu:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    average_accuracy = correct/total\n",
        "    tqdm.write(f'{tag} accuracy of the network: {100*average_accuracy:.02f}%')\n",
        "\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            if use_gpu:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "        tqdm.write(f'{tag} accuracy of {classes[i]} = {100*class_correct[i]/class_total[i]:.02f}%')\n",
        "    \n",
        "    return average_accuracy\n",
        "\n",
        "\n",
        "def train_network(net, lr, epochs, batch_size, criterion=None,\n",
        "                  train_transforms=default_train_transform, \n",
        "                  use_gpu=use_gpu): \n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "    if criterion is None:\n",
        "        # Note that CrossEntropyLoss has the Softmax built in!\n",
        "        # This is good for numerical stability. \n",
        "        # Read: https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    train_loader = get_train_loader(batch_size)\n",
        "    test_loader = get_test_loader(batch_size)\n",
        "    \n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        train_loss = train(net, train_loader, optimizer, criterion, epoch, use_gpu=use_gpu)\n",
        "        train_accuracy = test(net, train_loader, 'Train', use_gpu=use_gpu)\n",
        "        test_accuracy = test(net, test_loader, 'Test', use_gpu=use_gpu)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "    \n",
        "    return train_losses, train_accuracies, test_accuracies\n",
        "    \n",
        "\n",
        "def plot_results(train_losses, train_accuracies, test_accuracies):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    axes[0].plot(train_losses)\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    \n",
        "    axes[1].plot(train_accuracies)\n",
        "    axes[1].set_title('Training Accuracy')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    \n",
        "    axes[2].plot(test_accuracies)\n",
        "    axes[2].set_title('Testing Accuracy')\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('Accuracy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z7fg7toAbRJE"
      },
      "source": [
        "\n",
        "## 2.1. Training a classifier using only one fully connected Layer\n",
        "\n",
        "Implement a model to classify the images from Cifar-10 into ten categories using just one fully connected layer (remember that fully connected layers are called Linear in PyTorch).\n",
        "\n",
        "If you are new to PyTorch you may want to check out the tutorial on MNIST [here](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py).\n",
        "\n",
        "Fill in the code for LazyNet here.\n",
        "\n",
        "**Hints:**\n",
        " - Note that `nn.CrossEntropyLoss` has the Softmax built in for numerical stability. This means that the output layer of your network should be linear and not contain a Softmax.\n",
        " - You can use the `view()` function to flatten your input image to a vector e.g., if `x` is a `(100,3,4,4)` tensor then `x.view(-1, 3*4*4)` will flatten it into a vector of size `48`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YsSqlM8aYB7M",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "class LazyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO: Define model here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass for LazyNet\n",
        "        return x\n",
        "\n",
        "net = LazyNet()\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-2w5lEj84et",
        "colab_type": "text"
      },
      "source": [
        "#### Run the model for 50 epochs and report the plots and accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iHYGGCu-b_gE",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "train_losses, train_accuracies, test_accuracies = train_network(\n",
        "    net, \n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.01, \n",
        "    epochs=50, \n",
        "    batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlFRsBIi84ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results(train_losses, train_accuracies, test_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf1r46NZ84ez",
        "colab_type": "text"
      },
      "source": [
        "## 2.2. Training a classifier using multiple fully connected layers ##\n",
        "\n",
        "Implement a model for the same classification task using multiple fully connected layers.\n",
        "\n",
        "Start with a fully connected layer that maps the data from image size (32 * 32 * 3) to a vector of size 120, followed by another fully connected that reduces the size to 84 and finally a layer that maps the vector of size 84 to 10 classes.\n",
        "\n",
        "Use any activation you want.\n",
        "\n",
        "Fill in the code for BoringNet below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fuoYdwZ9gQq5",
        "colab": {}
      },
      "source": [
        "class BoringNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO: Define model here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass for LazyNet\n",
        "        return x\n",
        "\n",
        "net = BoringNet()\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE4lmp-z84e2",
        "colab_type": "text"
      },
      "source": [
        "### Run the model for 50 epochs and report the plots and accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RHEbyiy84e3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses, train_accuracies, test_accuracies = train_network(\n",
        "    net, \n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.01, \n",
        "    epochs=50, \n",
        "    batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7gwhaYp84e5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results(train_losses, train_accuracies, test_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcIXPU9o84e7",
        "colab_type": "text"
      },
      "source": [
        "### Question\n",
        "\n",
        "Try training this model with and without activations. How does the activations (such as ReLU) affect the training process and why?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka7ybdHi84e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3KpwTHf84e_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 2.3. Training a classifier using convolutions ##\n",
        "\n",
        "Implement a model using convolutional, pooling and fully connected layers.\n",
        "\n",
        "You are free to choose any parameters for these layers (we would like you to play around with some values).\n",
        "\n",
        "Fill in the code for CoolNet below. Explain why you have chosen these layers and how they affected the performance. Analyze the behavior of your model and report the plots in your report file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wwU7Lxs84e_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CoolNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO: Define model here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass for LazyNet\n",
        "        \n",
        "        return x\n",
        "\n",
        "net = CoolNet()\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLbwxHnv84fC",
        "colab_type": "text"
      },
      "source": [
        "### Run the model for 50 epochs and report the plots and accuracies "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZIHJOx_p84fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses, train_accuracies, test_accuracies = train_network(\n",
        "    net, \n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.01, \n",
        "    epochs=50, \n",
        "    batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a47cZGq884fE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results(train_losses, train_accuracies, test_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdsbz_7p84fH",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1. How does batch size affect training?\n",
        "\n",
        "Try using three different values for batch size. How do these values affect training and why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPNcgX0h84fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_losses, train_accuracies, test_accuracies = train_network(net, lr=0.01, epochs=50, batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98nok-F584fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot_results(train_losses, train_accuracies, test_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TR6l4_584fL",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2. How does learning rate work?\n",
        "\n",
        "When you are trying to train a neural network it is really hard to choose a proper learning rate. \n",
        "\n",
        "Try to train your model with different learning rates and plot the training accuracy, test accuracy and loss and compare the training progress for learning rates = 10, 0.1, 0.01, 0.0001.\n",
        "\n",
        "Analyze the results and choose the best one. Why did you choose this value?\n",
        "\n",
        "During training it is often useful to reduce learning rate as the training progresses (why?). \n",
        "Fill in `adjust_learning_rate` in `BaseModel` in `models.py` to reduce the learning rate by 10% every 50 epoch and observe the behavior of network for 150 epochs. \n",
        "Turn in your plots in `Report.pdf`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7V03_lnCgRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an3_bp-d84fM",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3. Data Augmentation\n",
        "\n",
        "Most of the popular computer vision datasets have tens of thousands of images. \n",
        "\n",
        "Cifar-10 is a dataset of 60000 32x32 colour images in 10 classes, which can be relatively small in compare to ImageNet which has 1M images. \n",
        "\n",
        "The more the number of parameters is, the more likely our model is to overfit to the small dataset. \n",
        "As you might have already faced this issue while training the CoolNet, after some iterations the training accuracy reaches its maximum (saturates) while the test accuracy is still relatively low. \n",
        "\n",
        "To solve this problem, we use the data augmentation to help the network avoid overfitting.\n",
        "\n",
        "Add data transformations in to the class below and compare the results. You are free to use any type and any number of data augmentation techniques.\n",
        "\n",
        "Just be aware that data augmentation should just happen during training phase. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNRQ5fhT84fN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    # TODO: Add data augmentations here\n",
        "    # You can find a list of transforms here:\n",
        "    #  https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6ntBrXZ84fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses, train_accuracies, test_accuracies = train_network(\n",
        "    net, \n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    train_transforms=train_transform,\n",
        "    lr=0.01, \n",
        "    epochs=50, \n",
        "    batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QENsIio684fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results(train_losses, train_accuracies, test_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9JVV5AX84fV",
        "colab_type": "text"
      },
      "source": [
        "#### Question\n",
        "How does the model trained with data augmentation compared to the model trained without?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRBpbdy784fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUnfgA5G84fX",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4. Change the loss function\n",
        "\n",
        "Try Mean Squared Error loss instead of Cross Entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfAh2MwQ84fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses, train_accuracies, test_accuracies = train_network(\n",
        "    net, \n",
        "    criterion=nn.MSELoss(),\n",
        "    lr=0.01, \n",
        "    epochs=50, \n",
        "    batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TePejy2984fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results(train_losses, train_accuracies, test_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDVB6Jl984fe",
        "colab_type": "text"
      },
      "source": [
        "#### Question:\n",
        "How does this affects the results? Explain why you think this is happening."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D4SStPF84fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaH9ibDt_EJk",
        "colab_type": "text"
      },
      "source": [
        "## Turning In\n",
        "\n",
        "You're done! You just need to turn in the notebook file.\n",
        "\n",
        "Go to `File > Download .ipynb` and download the file as `hw4.ipynb`. Turn in only this file.\n",
        "\n",
        "Make sure that you've answered all questions and all plots are correct."
      ]
    }
  ]
}